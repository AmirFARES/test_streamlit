import streamlit as st
import requests

# Hugging Face Inference API URL
API_URL = "https://0228-34-125-224-246.ngrok-free.app/generate"
HF_API_TOKEN = "your_huggingface_token"  # Optional: leave "" if model is public

# Streamlit page config
st.set_page_config(page_title="Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ù…Ø¹ Ù†Ù…ÙˆØ°Ø¬ Ø¬ÙŠØ³", page_icon="ğŸ¤–")
st.title(f"ğŸ’¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ù…Ø¹ Ù†Ù…ÙˆØ°Ø¬ Ø¬ÙŠØ³")

# Arabic system prompt (Customer Support style)
SYSTEM_PROMPT = """
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙŠØªØ­Ø¯Ø« Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆÙ…Ù‡Ù…ØªÙƒ Ù‡ÙŠ ØªÙ‚Ø¯ÙŠÙ… Ø¯Ø¹Ù… Ø¹Ù…Ù„Ø§Ø¡ Ø§Ø­ØªØ±Ø§ÙÙŠ.
ÙƒÙ† ÙˆØ¯ÙˆØ¯Ù‹Ø§ØŒ ÙˆØ§Ø¶Ø­Ù‹Ø§ØŒ ÙˆØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¨Ø£ÙØ¶Ù„ Ø´ÙƒÙ„ Ù…Ù…ÙƒÙ†.
"""

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display previous messages
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Chat input
prompt = st.chat_input("Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§...")

if prompt:
    # Save user message
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Combine system prompt + chat history
    full_prompt = f"ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…: {SYSTEM_PROMPT.strip()}\n"
    for msg in st.session_state.messages:
        if msg["role"] == "user":
            full_prompt += f"Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {msg['content']}\n"
        elif msg["role"] == "assistant":
            full_prompt += f"Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯: {msg['content']}\n"
    full_prompt += "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯:"

    # Prepare headers and payload
    headers = {"Authorization": f"Bearer {HF_API_TOKEN}"} if HF_API_TOKEN else {}
    payload = {"inputs": full_prompt}

    # Call HF API
    try:
        response = requests.post(API_URL, headers=headers, json=payload)
        if response.status_code == 200:
            output = response.json()
            generated_text = output[0]["generated_text"]
            model_reply = generated_text[len(full_prompt):].strip()
        else:
            model_reply = "âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù†Ù…ÙˆØ°Ø¬."
    except Exception as e:
        model_reply = f"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}"

    # Save and display assistant reply
    st.session_state.messages.append({"role": "assistant", "content": model_reply})
    with st.chat_message("assistant"):
        st.markdown(model_reply)
